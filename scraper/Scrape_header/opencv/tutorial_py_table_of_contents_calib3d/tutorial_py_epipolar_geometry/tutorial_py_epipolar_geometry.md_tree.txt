(Table of Contents)
--Goal (h2)
--Basic Concepts (h2)
--Code (h2)
Find epilines corresponding to points in right image (second image) and# drawing its lines on left imagelines1 = [cv.computeCorrespondEpilines](../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7 "../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7")(pts2.reshape(-1,1,2), 2,F)lines1 = lines1.reshape(-1,3)img5,img6 = drawlines(img1,img2,lines1,pts1,pts2)# Find epilines corresponding to points in left image (first image) and# drawing its lines on right imagelines2 = [cv.computeCorrespondEpilines](../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7 "../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7")(pts1.reshape(-1,1,2), 1,F)lines2 = lines2.reshape(-1,3)img3,img4 = drawlines(img2,img1,lines2,pts2,pts1)plt.subplot(121),plt.imshow(img5)plt.subplot(122),plt.imshow(img3)plt.show() Below is the result we get: (h1)
--Additional Resources (h2)
--Exercises (h2)


(Page path)
(1)  > (2) Goal

(Segment 1)
# (h1)
[]
##Goal (h2)

In this section,

* We will learn about the basics of multiview geometry
* We will see what is epipole, epipolar lines, epipolar constraint etc.




--------------------------------------------------------------------------------
(Table of Contents)
--Goal (h2)
--Basic Concepts (h2)
--Code (h2)
Find epilines corresponding to points in right image (second image) and# drawing its lines on left imagelines1 = [cv.computeCorrespondEpilines](../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7 "../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7")(pts2.reshape(-1,1,2), 2,F)lines1 = lines1.reshape(-1,3)img5,img6 = drawlines(img1,img2,lines1,pts1,pts2)# Find epilines corresponding to points in left image (first image) and# drawing its lines on right imagelines2 = [cv.computeCorrespondEpilines](../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7 "../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7")(pts1.reshape(-1,1,2), 1,F)lines2 = lines2.reshape(-1,3)img3,img4 = drawlines(img2,img1,lines2,pts2,pts1)plt.subplot(121),plt.imshow(img5)plt.subplot(122),plt.imshow(img3)plt.show() Below is the result we get: (h1)
--Additional Resources (h2)
--Exercises (h2)


(Page path)
(1)  > (2) Basic Concepts

(Segment 2)
# (h1)
[]
##Basic Concepts (h2)

When we take an image using pin-hole camera, we loose an important information, ie depth of the image. Or how far is each point in the image from the camera because it is a 3D-to-2D conversion. So it is an important question whether we can find the depth information using these cameras. And the answer is to use more than one camera. Our eyes works in similar way where we use two cameras (two eyes) which is called stereo vision. So let's see what OpenCV provides in this field.

(*Learning OpenCV* by Gary Bradsky has a lot of information in this field.)

Before going to depth images, let's first understand some basic concepts in multiview geometry. In this section we will deal with epipolar geometry. See the image below which shows a basic setup with two cameras taking the image of same scene.

![epipolar.jpg](../../epipolar.jpg)

image
 If we are using only the left camera, we can't find the 3D point corresponding to the point \(x\) in image because every point on the line \(OX\) projects to the same point on the image plane. But consider the right image also. Now different points on the line \(OX\) projects to different points ( \(x'\)) in right plane. So with these two images, we can triangulate the correct 3D point. This is the whole idea.

The projection of the different points on \(OX\) form a line on right plane (line \(l'\)). We call it **epiline** corresponding to the point \(x\). It means, to find the point \(x\) on the right image, search along this epiline. It should be somewhere on this line (Think of it this way, to find the matching point in other image, you need not search the whole image, just search along the epiline. So it provides better performance and accuracy). This is called **Epipolar Constraint**. Similarly all points will have its corresponding epilines in the other image. The plane \(XOO'\) is called **Epipolar Plane**.

\(O\) and \(O'\) are the camera centers. From the setup given above, you can see that projection of right camera \(O'\) is seen on the left image at the point, \(e\). It is called the **epipole**. Epipole is the point of intersection of line through camera centers and the image planes. Similarly \(e'\) is the epipole of the left camera. In some cases, you won't be able to locate the epipole in the image, they may be outside the image (which means, one camera doesn't see the other).

All the epilines pass through its epipole. So to find the location of epipole, we can find many epilines and find their intersection point.

So in this session, we focus on finding epipolar lines and epipoles. But to find them, we need two more ingredients, **Fundamental Matrix (F)** and **Essential Matrix (E)**. Essential Matrix contains the information about translation and rotation, which describe the location of the second camera relative to the first in global coordinates. See the image below (Image courtesy: Learning OpenCV by Gary Bradsky):

![essential_matrix.jpg](../../essential_matrix.jpg)

image
 But we prefer measurements to be done in pixel coordinates, right? Fundamental Matrix contains the same information as Essential Matrix in addition to the information about the intrinsics of both cameras so that we can relate the two cameras in pixel coordinates. (If we are using rectified images and normalize the point by dividing by the focal lengths, \(F=E\)). In simple words, Fundamental Matrix F, maps a point in one image to a line (epiline) in the other image. This is calculated from matching points from both the images. A minimum of 8 such points are required to find the fundamental matrix (while using 8-point algorithm). More points are preferred and use RANSAC to get a more robust result.




--------------------------------------------------------------------------------
(Table of Contents)
--Goal (h2)
--Basic Concepts (h2)
--Code (h2)
Find epilines corresponding to points in right image (second image) and# drawing its lines on left imagelines1 = [cv.computeCorrespondEpilines](../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7 "../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7")(pts2.reshape(-1,1,2), 2,F)lines1 = lines1.reshape(-1,3)img5,img6 = drawlines(img1,img2,lines1,pts1,pts2)# Find epilines corresponding to points in left image (first image) and# drawing its lines on right imagelines2 = [cv.computeCorrespondEpilines](../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7 "../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7")(pts1.reshape(-1,1,2), 1,F)lines2 = lines2.reshape(-1,3)img3,img4 = drawlines(img2,img1,lines2,pts2,pts1)plt.subplot(121),plt.imshow(img5)plt.subplot(122),plt.imshow(img3)plt.show() Below is the result we get: (h1)
--Additional Resources (h2)
--Exercises (h2)


(Page path)
(1)  > (2) Code

(Segment 3)
# (h1)
[]
##Code (h2)

So first we need to find as many possible matches between two images to find the fundamental matrix. For this, we use SIFT descriptors with FLANN based matcher and ratio test. 

import numpy as npimport cv2 as cvfrom matplotlib import pyplot as pltimg1 = [cv.imread](../../d4/da8/group__imgcodecs.html#ga288b8b3da0892bd651fce07b3bbd3a56 "../../d4/da8/group__imgcodecs.html#ga288b8b3da0892bd651fce07b3bbd3a56")('myleft.jpg', cv.IMREAD\_GRAYSCALE) #queryimage # left imageimg2 = [cv.imread](../../d4/da8/group__imgcodecs.html#ga288b8b3da0892bd651fce07b3bbd3a56 "../../d4/da8/group__imgcodecs.html#ga288b8b3da0892bd651fce07b3bbd3a56")('myright.jpg', cv.IMREAD\_GRAYSCALE) #trainimage # right imagesift = cv.SIFT\_create()# find the keypoints and descriptors with SIFTkp1, des1 = sift.detectAndCompute(img1,None)kp2, des2 = sift.detectAndCompute(img2,None)# FLANN parametersFLANN\_INDEX\_KDTREE = 1index\_params = dict(algorithm = FLANN\_INDEX\_KDTREE, trees = 5)search\_params = dict(checks=50)flann = [cv.FlannBasedMatcher](../../dc/de2/classcv_1_1FlannBasedMatcher.html "../../dc/de2/classcv_1_1FlannBasedMatcher.html")(index\_params,search\_params)matches = flann.knnMatch(des1,des2,k=2)pts1 = []pts2 = []# ratio test as per Lowe's paperfor i,(m,n) in enumerate(matches): if m.distance < 0.8\*n.distance: pts2.append(kp2[m.trainIdx].pt) pts1.append(kp1[m.queryIdx].pt) Now we have the list of best matches from both the images. Let's find the Fundamental Matrix. 

pts1 = np.int32(pts1)pts2 = np.int32(pts2)F, mask = [cv.findFundamentalMat](../../d9/d0c/group__calib3d.html#gae850fad056e407befb9e2db04dd9e509 "../../d9/d0c/group__calib3d.html#gae850fad056e407befb9e2db04dd9e509")(pts1,pts2,cv.FM\_LMEDS)# We select only inlier pointspts1 = pts1[mask.ravel()==1]pts2 = pts2[mask.ravel()==1] Next we find the epilines. Epilines corresponding to the points in first image is drawn on second image. So mentioning of correct images are important here. We get an array of lines. So we define a new function to draw these lines on the images. 

def drawlines(img1,img2,lines,pts1,pts2): ''' img1 - image on which we draw the epilines for the points in img2 lines - corresponding epilines ''' r,c = img1.shape img1 = [cv.cvtColor](../../d8/d01/group__imgproc__color__conversions.html#ga397ae87e1288a81d2363b61574eb8cab "../../d8/d01/group__imgproc__color__conversions.html#ga397ae87e1288a81d2363b61574eb8cab")(img1,cv.COLOR\_GRAY2BGR) img2 = [cv.cvtColor](../../d8/d01/group__imgproc__color__conversions.html#ga397ae87e1288a81d2363b61574eb8cab "../../d8/d01/group__imgproc__color__conversions.html#ga397ae87e1288a81d2363b61574eb8cab")(img2,cv.COLOR\_GRAY2BGR) for r,pt1,pt2 in zip(lines,pts1,pts2): color = tuple(np.random.randint(0,255,3).tolist()) x0,y0 = map(int, [0, -r[2]/r[1] ]) x1,y1 = map(int, [c, -(r[2]+r[0]\*c)/r[1] ]) img1 = [cv.line](../../d6/d6e/group__imgproc__draw.html#ga7078a9fae8c7e7d13d24dac2520ae4a2 "../../d6/d6e/group__imgproc__draw.html#ga7078a9fae8c7e7d13d24dac2520ae4a2")(img1, (x0,y0), (x1,y1), color,1) img1 = [cv.circle](../../d6/d6e/group__imgproc__draw.html#gaf10604b069374903dbd0f0488cb43670 "../../d6/d6e/group__imgproc__draw.html#gaf10604b069374903dbd0f0488cb43670")(img1,tuple(pt1),5,color,-1) img2 = [cv.circle](../../d6/d6e/group__imgproc__draw.html#gaf10604b069374903dbd0f0488cb43670 "../../d6/d6e/group__imgproc__draw.html#gaf10604b069374903dbd0f0488cb43670")(img2,tuple(pt2),5,color,-1) return img1,img2 Now we find the epilines in both the images and draw them. 




--------------------------------------------------------------------------------
(Table of Contents)
--Goal (h2)
--Basic Concepts (h2)
--Code (h2)
Find epilines corresponding to points in right image (second image) and# drawing its lines on left imagelines1 = [cv.computeCorrespondEpilines](../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7 "../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7")(pts2.reshape(-1,1,2), 2,F)lines1 = lines1.reshape(-1,3)img5,img6 = drawlines(img1,img2,lines1,pts1,pts2)# Find epilines corresponding to points in left image (first image) and# drawing its lines on right imagelines2 = [cv.computeCorrespondEpilines](../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7 "../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7")(pts1.reshape(-1,1,2), 1,F)lines2 = lines2.reshape(-1,3)img3,img4 = drawlines(img2,img1,lines2,pts2,pts1)plt.subplot(121),plt.imshow(img5)plt.subplot(122),plt.imshow(img3)plt.show() Below is the result we get: (h1)
--Additional Resources (h2)
--Exercises (h2)


(Page path)
(1) Find epilines corresponding to points in right image (second image) and# drawing its lines on left imagelines1 = [cv.computeCorrespondEpilines](../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7 "../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7")(pts2.reshape(-1,1,2), 2,F)lines1 = lines1.reshape(-1,3)img5,img6 = drawlines(img1,img2,lines1,pts1,pts2)# Find epilines corresponding to points in left image (first image) and# drawing its lines on right imagelines2 = [cv.computeCorrespondEpilines](../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7 "../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7")(pts1.reshape(-1,1,2), 1,F)lines2 = lines2.reshape(-1,3)img3,img4 = drawlines(img2,img1,lines2,pts2,pts1)plt.subplot(121),plt.imshow(img5)plt.subplot(122),plt.imshow(img3)plt.show() Below is the result we get: > (2) Additional Resources

(Segment 4)
#Find epilines corresponding to points in right image (second image) and# drawing its lines on left imagelines1 = [cv.computeCorrespondEpilines](../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7 "../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7")(pts2.reshape(-1,1,2), 2,F)lines1 = lines1.reshape(-1,3)img5,img6 = drawlines(img1,img2,lines1,pts1,pts2)# Find epilines corresponding to points in left image (first image) and# drawing its lines on right imagelines2 = [cv.computeCorrespondEpilines](../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7 "../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7")(pts1.reshape(-1,1,2), 1,F)lines2 = lines2.reshape(-1,3)img3,img4 = drawlines(img2,img1,lines2,pts2,pts1)plt.subplot(121),plt.imshow(img5)plt.subplot(122),plt.imshow(img3)plt.show() Below is the result we get: (h1)

![epiresult.jpg](../../epiresult.jpg)

image
 You can see in the left image that all epilines are converging at a point outside the image at right side. That meeting point is the epipole.

For better results, images with good resolution and many non-planar points should be used.


##Additional Resources (h2)




--------------------------------------------------------------------------------
(Table of Contents)
--Goal (h2)
--Basic Concepts (h2)
--Code (h2)
Find epilines corresponding to points in right image (second image) and# drawing its lines on left imagelines1 = [cv.computeCorrespondEpilines](../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7 "../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7")(pts2.reshape(-1,1,2), 2,F)lines1 = lines1.reshape(-1,3)img5,img6 = drawlines(img1,img2,lines1,pts1,pts2)# Find epilines corresponding to points in left image (first image) and# drawing its lines on right imagelines2 = [cv.computeCorrespondEpilines](../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7 "../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7")(pts1.reshape(-1,1,2), 1,F)lines2 = lines2.reshape(-1,3)img3,img4 = drawlines(img2,img1,lines2,pts2,pts1)plt.subplot(121),plt.imshow(img5)plt.subplot(122),plt.imshow(img3)plt.show() Below is the result we get: (h1)
--Additional Resources (h2)
--Exercises (h2)


(Page path)
(1) Find epilines corresponding to points in right image (second image) and# drawing its lines on left imagelines1 = [cv.computeCorrespondEpilines](../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7 "../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7")(pts2.reshape(-1,1,2), 2,F)lines1 = lines1.reshape(-1,3)img5,img6 = drawlines(img1,img2,lines1,pts1,pts2)# Find epilines corresponding to points in left image (first image) and# drawing its lines on right imagelines2 = [cv.computeCorrespondEpilines](../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7 "../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7")(pts1.reshape(-1,1,2), 1,F)lines2 = lines2.reshape(-1,3)img3,img4 = drawlines(img2,img1,lines2,pts2,pts1)plt.subplot(121),plt.imshow(img5)plt.subplot(122),plt.imshow(img3)plt.show() Below is the result we get: > (2) Exercises

(Segment 5)
#Find epilines corresponding to points in right image (second image) and# drawing its lines on left imagelines1 = [cv.computeCorrespondEpilines](../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7 "../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7")(pts2.reshape(-1,1,2), 2,F)lines1 = lines1.reshape(-1,3)img5,img6 = drawlines(img1,img2,lines1,pts1,pts2)# Find epilines corresponding to points in left image (first image) and# drawing its lines on right imagelines2 = [cv.computeCorrespondEpilines](../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7 "../../d9/d0c/group__calib3d.html#ga19e3401c94c44b47c229be6e51d158b7")(pts1.reshape(-1,1,2), 1,F)lines2 = lines2.reshape(-1,3)img3,img4 = drawlines(img2,img1,lines2,pts2,pts1)plt.subplot(121),plt.imshow(img5)plt.subplot(122),plt.imshow(img3)plt.show() Below is the result we get: (h1)

![epiresult.jpg](../../epiresult.jpg)

image
 You can see in the left image that all epilines are converging at a point outside the image at right side. That meeting point is the epipole.

For better results, images with good resolution and many non-planar points should be used.


##Exercises (h2)

1. One important topic is the forward movement of camera. Then epipoles will be seen at the same locations in both with epilines emerging from a fixed point. [See this discussion](http://answers.opencv.org/question/17912/location-of-epipole/ "http://answers.opencv.org/question/17912/location-of-epipole/").
2. Fundamental Matrix estimation is sensitive to quality of matches, outliers etc. It becomes worse when all selected matches lie on the same plane. [Check this discussion](http://answers.opencv.org/question/18125/epilines-not-correct/ "http://answers.opencv.org/question/18125/epilines-not-correct/").

---

Generated on Wed Oct 4 2023 23:37:11 for OpenCV by Â [![doxygen](../../doxygen.png)](http://www.doxygen.org/index.html "http://www.doxygen.org/index.html") 1.8.13

//<![CDATA[
addTutorialsButtons();
//]]>




--------------------------------------------------------------------------------
